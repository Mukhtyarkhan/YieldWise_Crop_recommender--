{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "42/42 [==============================] - 2s 13ms/step - loss: 3.0390 - accuracy: 0.1053 - val_loss: 2.9743 - val_accuracy: 0.1670\n",
      "Epoch 2/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 2.8849 - accuracy: 0.2523 - val_loss: 2.8142 - val_accuracy: 0.2523\n",
      "Epoch 3/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 2.7025 - accuracy: 0.3667 - val_loss: 2.6002 - val_accuracy: 0.4250\n",
      "Epoch 4/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 2.4686 - accuracy: 0.5258 - val_loss: 2.3540 - val_accuracy: 0.5580\n",
      "Epoch 5/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 2.2224 - accuracy: 0.5917 - val_loss: 2.1060 - val_accuracy: 0.5943\n",
      "Epoch 6/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 1.9833 - accuracy: 0.6697 - val_loss: 1.8850 - val_accuracy: 0.6148\n",
      "Epoch 7/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 1.7747 - accuracy: 0.6985 - val_loss: 1.6955 - val_accuracy: 0.6864\n",
      "Epoch 8/25\n",
      "42/42 [==============================] - 0s 8ms/step - loss: 1.5945 - accuracy: 0.7174 - val_loss: 1.5356 - val_accuracy: 0.6966\n",
      "Epoch 9/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 1.4407 - accuracy: 0.7227 - val_loss: 1.3923 - val_accuracy: 0.7898\n",
      "Epoch 10/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 1.3069 - accuracy: 0.8000 - val_loss: 1.2809 - val_accuracy: 0.7307\n",
      "Epoch 11/25\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 1.1961 - accuracy: 0.8379 - val_loss: 1.1762 - val_accuracy: 0.8045\n",
      "Epoch 12/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 1.1027 - accuracy: 0.8470 - val_loss: 1.0929 - val_accuracy: 0.8273\n",
      "Epoch 13/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 1.0139 - accuracy: 0.8795 - val_loss: 1.0156 - val_accuracy: 0.8648\n",
      "Epoch 14/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.9441 - accuracy: 0.9030 - val_loss: 0.9546 - val_accuracy: 0.8545\n",
      "Epoch 15/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.8787 - accuracy: 0.8932 - val_loss: 0.8884 - val_accuracy: 0.8761\n",
      "Epoch 16/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.8242 - accuracy: 0.9144 - val_loss: 0.8364 - val_accuracy: 0.8966\n",
      "Epoch 17/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.7727 - accuracy: 0.9318 - val_loss: 0.7932 - val_accuracy: 0.8784\n",
      "Epoch 18/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.7250 - accuracy: 0.9227 - val_loss: 0.7526 - val_accuracy: 0.8875\n",
      "Epoch 19/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6804 - accuracy: 0.9409 - val_loss: 0.7078 - val_accuracy: 0.9045\n",
      "Epoch 20/25\n",
      "42/42 [==============================] - 0s 7ms/step - loss: 0.6452 - accuracy: 0.9341 - val_loss: 0.6775 - val_accuracy: 0.9125\n",
      "Epoch 21/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.6079 - accuracy: 0.9462 - val_loss: 0.6428 - val_accuracy: 0.9125\n",
      "Epoch 22/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5760 - accuracy: 0.9485 - val_loss: 0.6128 - val_accuracy: 0.9170\n",
      "Epoch 23/25\n",
      "42/42 [==============================] - 0s 9ms/step - loss: 0.5463 - accuracy: 0.9523 - val_loss: 0.5871 - val_accuracy: 0.9091\n",
      "Epoch 24/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.5197 - accuracy: 0.9462 - val_loss: 0.5613 - val_accuracy: 0.9250\n",
      "Epoch 25/25\n",
      "42/42 [==============================] - 0s 6ms/step - loss: 0.4929 - accuracy: 0.9598 - val_loss: 0.5396 - val_accuracy: 0.9170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "#mport streamlit as st\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Load the crop dataset\n",
    "df = pd.read_csv(r'D:\\Data Sicence bootcamp\\DS_Bootcamp_Final_Project\\crop.csv')\n",
    "\n",
    "# Define a dictionary to map crop names to numeric labels\n",
    "crop_names = {\n",
    "    \"rice\": 0,\n",
    "    \"maize\": 1,\n",
    "    \"jute\": 2,\n",
    "    \"cotton\": 3,\n",
    "    \"coconut\": 4,\n",
    "    \"papaya\": 5,\n",
    "    \"orange\": 6,\n",
    "    \"apple\": 7,\n",
    "    \"muskmelon\": 8,\n",
    "    \"watermelon\": 9,\n",
    "    \"grapes\": 10,\n",
    "    \"mango\": 11,\n",
    "    \"banana\": 12,\n",
    "    \"pomegranate\": 13,\n",
    "    \"lentil\": 14,\n",
    "    \"blackgram\": 15,\n",
    "    \"mungbean\": 16,\n",
    "    \"mothbeans\": 17,\n",
    "    \"pigeonpeas\": 18,\n",
    "    \"kidneybeans\": 19,\n",
    "    \"chickpea\": 20,\n",
    "    \"coffee\": 21\n",
    "}\n",
    "\n",
    "# Inverse mapping for numeric labels to crop names\n",
    "#inverse_crop_names = {v: k for k, v in crop_names.items()}\n",
    "\n",
    "# Preprocess the data\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "y = y.map(crop_names)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Normalize features using Min-Max scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Define the neural network model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_train.shape[1],)),  # Input layer with the number of features\n",
    "    keras.layers.Dense(128, activation='relu'),  # Hidden layer with 128 neurons and ReLU activation\n",
    "    keras.layers.Dense(len(crop_names), activation='softmax')  # Output layer with softmax activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',  # Use sparse categorical cross-entropy for multi-class classification\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=25, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Save the model weights\n",
    "\n",
    "model_filename=(r'D:\\Data Sicence bootcamp\\DS_Bootcamp_Final_Project')\n",
    "model.save(\"model_filename.h5\")\n",
    "# Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
